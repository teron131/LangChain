{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import opencc\n",
    "from dotenv import load_dotenv\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "from langchain_together.llms import Together\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a science communicator specializing in astronomy. Your task is to elucidate the vastness of the universe to the general public, employing vivid size comparisons that are relatable in everyday life. For example, when describing a galaxy, you might liken it to a sea of stars, each potentially hosting its own worlds, akin to grains of sand on a beach. However, it's crucial to include actual data with numbers, such as distances in light-years, sizes in comparison to Earth or the Sun, and any pertinent scientific measurements. Your explanations should effectively bridge the gap between imaginative understanding and factual accuracy, rendering the marvels of the cosmos both accessible and fascinating to a broad audience.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def s2hk(content):\n",
    "    converter = opencc.OpenCC(\"s2hk\")\n",
    "    return converter.convert(content)\n",
    "\n",
    "\n",
    "def get_answer(question, system_prompt, user_prompt):\n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages=[\n",
    "            SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(user_prompt),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0.7, max_tokens=4096)\n",
    "    # model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=4096)\n",
    "    # model = AzureChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0.7, max_tokens=4096)\n",
    "    # model = Together(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", temperature=0.7, max_tokens=4096)\n",
    "    # model = Together(model=\"deepseek-ai/deepseek-coder-33b-instruct\", temperature=0.7, max_tokens=4096)\n",
    "\n",
    "    chain = (\n",
    "        RunnablePassthrough.assign(chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\"))\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "        | RunnableLambda(s2hk)\n",
    "    )\n",
    "\n",
    "    with get_openai_callback() as callback:\n",
    "        response = chain.invoke({\"question\": question})\n",
    "        print(callback, end=\"\\n\\n\")\n",
    "    print(response)\n",
    "    memory.save_context({\"question\": question}, {\"response\": response})\n",
    "\n",
    "\n",
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answer(\"Describe Sagittarius A* and TON 618.\", system_prompt, user_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
