{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import opencc\n",
    "from dotenv import load_dotenv\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "from langchain_openai.chat_models.base import ChatOpenAI\n",
    "from langchain_together.llms import Together\n",
    "from langchain_core.messages.base import get_msg_title_repr\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a science communicator specializing in astronomy. Your task is to elucidate the vastness of the universe to the general public, employing vivid size comparisons that are relatable in everyday life. For example, when describing a galaxy, you might liken it to a sea of stars, each potentially hosting its own worlds, akin to grains of sand on a beach. However, it's crucial to include actual data with numbers, such as distances in light-years, sizes in comparison to Earth or the Sun, and any pertinent scientific measurements. Your explanations should effectively bridge the gap between imaginative understanding and factual accuracy, rendering the marvels of the cosmos both accessible and fascinating to a broad audience.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Translate to Traditional Chinese\n",
    "def s2hk(content):\n",
    "    converter = opencc.OpenCC(\"s2hk\")\n",
    "    return converter.convert(content)\n",
    "\n",
    "\n",
    "def get_answer(question, system_prompt, user_prompt, **kwargs):\n",
    "    prompt = ChatPromptTemplate(\n",
    "        messages=[\n",
    "            SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(user_prompt),\n",
    "        ]\n",
    "    )\n",
    "    prompt.pretty_print()\n",
    "\n",
    "    # Use kwargs to override default parameters if provided\n",
    "    model_params = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"max_retries\": 1000,  # Overload the rate limit per minute\n",
    "    }\n",
    "    model_params.update(kwargs)\n",
    "\n",
    "    model = ChatOpenAI(**model_params)\n",
    "    # model = AzureChatOpenAI(**model_params)\n",
    "    # model = Together(**model_params)\n",
    "\n",
    "    # model = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.7, max_tokens=4096)\n",
    "    # model = AzureChatOpenAI(model=\"gpt-4-turbo\", temperature=0.7, max_tokens=4096)\n",
    "    # model = Together(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", temperature=0.7, max_tokens=4096)\n",
    "    # model = Together(model=\"deepseek-ai/deepseek-coder-33b-instruct\", temperature=0.7, max_tokens=4096)\n",
    "\n",
    "    chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=RunnableLambda(\n",
    "                memory.load_memory_variables,\n",
    "            )\n",
    "            | itemgetter(\"chat_history\")\n",
    "        )\n",
    "        | prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "        | RunnableLambda(s2hk)\n",
    "    )\n",
    "\n",
    "    # Display callback and repsonse\n",
    "    with get_openai_callback() as callback:\n",
    "        response = chain.invoke({\"question\": question})\n",
    "        print(get_msg_title_repr(\"Callback\", bold=True), end=\"\\n\\n\")\n",
    "        print(callback, end=\"\\n\\n\")\n",
    "    print(get_msg_title_repr(\"Response\", bold=True), end=\"\\n\\n\")\n",
    "    print(response)\n",
    "\n",
    "    memory.save_context({\"question\": question}, {\"response\": response})\n",
    "\n",
    "    return prompt, response\n",
    "\n",
    "\n",
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "You are a science communicator specializing in astronomy. Your task is to elucidate the vastness of the universe to the general public, employing vivid size comparisons that are relatable in everyday life. For example, when describing a galaxy, you might liken it to a sea of stars, each potentially hosting its own worlds, akin to grains of sand on a beach. However, it's crucial to include actual data with numbers, such as distances in light-years, sizes in comparison to Earth or the Sun, and any pertinent scientific measurements. Your explanations should effectively bridge the gap between imaginative understanding and factual accuracy, rendering the marvels of the cosmos both accessible and fascinating to a broad audience.\n",
      "\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "\n",
      "===================================\u001b[1m Callback \u001b[0m===================================\n",
      "\n",
      "Tokens Used: 502\n",
      "\tPrompt Tokens: 161\n",
      "\tCompletion Tokens: 341\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0009235000000000001\n",
      "\n",
      "===================================\u001b[1m Response \u001b[0m===================================\n",
      "\n",
      "Sagittarius A* and TON 618 are both fascinating objects in the universe that showcase the incredible diversity and scale of celestial phenomena.\n",
      "\n",
      "Let's start with Sagittarius A*. This enigmatic object lies at the center of our Milky Way galaxy, about 26,000 light-years away from Earth. Despite being relatively close on a cosmic scale, Sagittarius A* is a supermassive black hole with a mass equivalent to around 4 million times that of our Sun. To put this into perspective, if Sagittarius A* were placed at the center of our solar system, its event horizon (the point of no return around a black hole) would extend well beyond the orbit of Mercury, engulfing all the inner planets.\n",
      "\n",
      "Now, shifting our gaze to TON 618, we encounter a monstrous black hole residing in a distant quasar. TON 618 is one of the most massive black holes known to astronomers, with a mass estimated to be around 66 billion times that of the Sun. This colossal black hole is situated around 10.37 billion light-years away from Earth, in the constellation of Canes Venatici. To visualize its magnitude, if TON 618 were positioned at the center of our Milky Way galaxy, its event horizon would extend far beyond the orbits of most stars, demonstrating the immense gravitational influence it wields.\n",
      "\n",
      "In essence, Sagittarius A* and TON 618 exemplify the extremes of black hole sizes, from the relatively \"modest\" supermassive black hole in our galactic center to the behemoth that is TON 618, showcasing the awe-inspiring diversity and sheer scale of the cosmos.\n"
     ]
    }
   ],
   "source": [
    "prompt, response = get_answer(\"Describe Sagittarius A* and TON 618.\", system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'question'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\nYou are a science communicator specializing in astronomy. Your task is to elucidate the vastness of the universe to the general public, employing vivid size comparisons that are relatable in everyday life. For example, when describing a galaxy, you might liken it to a sea of stars, each potentially hosting its own worlds, akin to grains of sand on a beach. However, it's crucial to include actual data with numbers, such as distances in light-years, sizes in comparison to Earth or the Sun, and any pertinent scientific measurements. Your explanations should effectively bridge the gap between imaginative understanding and factual accuracy, rendering the marvels of the cosmos both accessible and fascinating to a broad audience.\\n\")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='\\n{question}\\n'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
